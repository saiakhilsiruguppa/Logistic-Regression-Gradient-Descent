{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f079bd1-d8a8-4085-ab6d-b06886bab5e4",
   "metadata": {},
   "source": [
    "# Logistic Regression and Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa5ef9c-7eea-4123-900c-4787546c8e8f",
   "metadata": {},
   "source": [
    "The file LRTrain.csv contains information from 300 images of malignant (i.e. cancerous) and\n",
    "benign (i.e., non-cancerous) breast tissue. The data set describes attributes of the cell nuclei in\n",
    "each image. Each row of the dataset corresponds to one image. For each image, ten different\n",
    "attributes related to the cell nuclei are recorded:\n",
    "\n",
    "- radius (mean of distances from center to points on the perimeter)\n",
    "- texture (standard deviation of gray-scale values)\n",
    "- perimeter\n",
    "- area\n",
    "- smoothness (local variation in radius lengths)\n",
    "- compactness (perimeter2/ area - 1.0)\n",
    "- concavity (severity of concave portions of the contour)\n",
    "- concave points (number of concave portions of the contour)\n",
    "- symmetry\n",
    "- fractal dimension (a measure of how “complex” the perimeter is)\n",
    "\n",
    "Because each image contains multiple cell nuclei, three quantities are measured for each of the 10\n",
    "attributes above: the mean, standard error, and worst case value. This results in a total of 30\n",
    "features for each image. The goal of this assignment is to train a logistic regression classifier using\n",
    "gradient descent, which will then be used to predict whether or not each image was taken from\n",
    "cancerous tissue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1af7ef7-3abb-4358-b443-ad32602f6888",
   "metadata": {},
   "source": [
    "<img src=\"image.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad44e87-ddf6-48a6-9301-e4568db78cad",
   "metadata": {},
   "source": [
    "We can minimize the cost function using the Gradient Descent algorithm where we differentiate the cost function to move in the direction of the global minima point. We need to calculate the gradient at a point w for the negative log likelihood function which is:\n",
    "\n",
    "$\\frac{1}{n} \\sum_{i=1}^{n} (\\frac{1}{1+ \\exp^{{-w}^Tx_i}} - y_i).x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cae163-cd8b-42ed-aa02-bbe558d775ee",
   "metadata": {},
   "source": [
    "We can use a step size to update the weights accordingly.\n",
    "\n",
    "$ x(i+1) = x(i) - (step\\ size)* \\frac{dy}{dx} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd09133-d0e4-4f42-8623-c47c19d6ce00",
   "metadata": {},
   "source": [
    "Check if $|{\\frac{dy}{dx}}| \\le \\epsilon$ and terminate if yes. Otherwise increment $i$ and return to previous steps mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa70d17e-e770-422a-8c71-7063d7b82d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gurobi and numpy\n",
    "from gurobipy import *\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ecdd424-3982-4855-9056-924ae7b9ceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('LRTrain.csv')\n",
    "df_test = pd.read_csv('LRTest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d73463a-ba5c-4a0c-9e5c-4a05274ff8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.180</td>\n",
       "      <td>20.52</td>\n",
       "      <td>77.22</td>\n",
       "      <td>458.7</td>\n",
       "      <td>0.08013</td>\n",
       "      <td>0.04038</td>\n",
       "      <td>0.02383</td>\n",
       "      <td>0.01770</td>\n",
       "      <td>0.1739</td>\n",
       "      <td>0.05677</td>\n",
       "      <td>...</td>\n",
       "      <td>32.84</td>\n",
       "      <td>84.58</td>\n",
       "      <td>547.8</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.08862</td>\n",
       "      <td>0.1145</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2694</td>\n",
       "      <td>0.06878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.280</td>\n",
       "      <td>22.41</td>\n",
       "      <td>98.92</td>\n",
       "      <td>710.6</td>\n",
       "      <td>0.09057</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.05375</td>\n",
       "      <td>0.03263</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>0.06317</td>\n",
       "      <td>...</td>\n",
       "      <td>28.03</td>\n",
       "      <td>113.80</td>\n",
       "      <td>973.1</td>\n",
       "      <td>0.1301</td>\n",
       "      <td>0.32990</td>\n",
       "      <td>0.3630</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.09772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.760</td>\n",
       "      <td>14.74</td>\n",
       "      <td>94.87</td>\n",
       "      <td>668.7</td>\n",
       "      <td>0.08875</td>\n",
       "      <td>0.07780</td>\n",
       "      <td>0.04608</td>\n",
       "      <td>0.03528</td>\n",
       "      <td>0.1521</td>\n",
       "      <td>0.05912</td>\n",
       "      <td>...</td>\n",
       "      <td>17.93</td>\n",
       "      <td>114.20</td>\n",
       "      <td>880.8</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.20090</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>0.12510</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.08187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.190</td>\n",
       "      <td>23.81</td>\n",
       "      <td>92.87</td>\n",
       "      <td>610.7</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.13060</td>\n",
       "      <td>0.11150</td>\n",
       "      <td>0.06462</td>\n",
       "      <td>0.2235</td>\n",
       "      <td>0.06433</td>\n",
       "      <td>...</td>\n",
       "      <td>34.85</td>\n",
       "      <td>115.00</td>\n",
       "      <td>811.3</td>\n",
       "      <td>0.1559</td>\n",
       "      <td>0.40590</td>\n",
       "      <td>0.3744</td>\n",
       "      <td>0.17720</td>\n",
       "      <td>0.4724</td>\n",
       "      <td>0.10260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.876</td>\n",
       "      <td>19.40</td>\n",
       "      <td>63.95</td>\n",
       "      <td>298.3</td>\n",
       "      <td>0.10050</td>\n",
       "      <td>0.09697</td>\n",
       "      <td>0.06154</td>\n",
       "      <td>0.03029</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.06322</td>\n",
       "      <td>...</td>\n",
       "      <td>26.83</td>\n",
       "      <td>72.22</td>\n",
       "      <td>361.2</td>\n",
       "      <td>0.1559</td>\n",
       "      <td>0.23020</td>\n",
       "      <td>0.2644</td>\n",
       "      <td>0.09749</td>\n",
       "      <td>0.2622</td>\n",
       "      <td>0.08490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0       12.180         20.52           77.22      458.7          0.08013   \n",
       "1       15.280         22.41           98.92      710.6          0.09057   \n",
       "2       14.760         14.74           94.87      668.7          0.08875   \n",
       "3       14.190         23.81           92.87      610.7          0.09463   \n",
       "4        9.876         19.40           63.95      298.3          0.10050   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0           0.04038         0.02383              0.01770         0.1739   \n",
       "1           0.10520         0.05375              0.03263         0.1727   \n",
       "2           0.07780         0.04608              0.03528         0.1521   \n",
       "3           0.13060         0.11150              0.06462         0.2235   \n",
       "4           0.09697         0.06154              0.03029         0.1945   \n",
       "\n",
       "   fractal_dimension_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
       "0                 0.05677  ...          32.84            84.58       547.8   \n",
       "1                 0.06317  ...          28.03           113.80       973.1   \n",
       "2                 0.05912  ...          17.93           114.20       880.8   \n",
       "3                 0.06433  ...          34.85           115.00       811.3   \n",
       "4                 0.06322  ...          26.83            72.22       361.2   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1123            0.08862           0.1145               0.07431   \n",
       "1            0.1301            0.32990           0.3630               0.12260   \n",
       "2            0.1220            0.20090           0.2151               0.12510   \n",
       "3            0.1559            0.40590           0.3744               0.17720   \n",
       "4            0.1559            0.23020           0.2644               0.09749   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  diagnosis  \n",
       "0          0.2694                  0.06878          0  \n",
       "1          0.3175                  0.09772          1  \n",
       "2          0.3109                  0.08187          0  \n",
       "3          0.4724                  0.10260          1  \n",
       "4          0.2622                  0.08490          0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db7a61e8-964f-4d4a-a4a9-6ac19b641d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['diagnosis'].to_numpy()\n",
    "X_train = df_train.drop('diagnosis', axis=1).to_numpy()\n",
    "y_test = df_test['diagnosis'].to_numpy()\n",
    "X_test = df_test.drop('diagnosis', axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c3785de-07c5-481a-ae4e-c5d08bc817de",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 300\n",
    "d = 30\n",
    "gamma = 0.00003\n",
    "epsilon = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a10baad0-8b2c-45ca-8405-d3462446ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.zeros(d)\n",
    "total_grad = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1994fca5-315b-4508-bbdd-957145e66f7f",
   "metadata": {},
   "source": [
    "#### Define function for calculating the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f7ea833-3aa8-4d94-889d-098a11f712a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_function(w, X_train, y_train):\n",
    "    n = len(X_train)\n",
    "    d = len(w)\n",
    "    sum_of_grad = np.zeros(d)\n",
    "    \n",
    "    for i in range(n):\n",
    "        x_i = X_train[i]\n",
    "        y_i = y_train[i]\n",
    "        to_add = ((1/(1+np.exp(-1 * np.dot(w, x_i), dtype=np.float128))) - y_i) * x_i\n",
    "        sum_of_grad += to_add\n",
    "    grad = sum_of_grad/n\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d25e89-5bc5-4397-8b73-4526374c3c39",
   "metadata": {},
   "source": [
    "#### Define function for computing weights for logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "809d49b5-2610-4b11-bf17-a5578410228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(w, X_train, y_train, iters, step, epsilon):\n",
    "    num_iter = 0\n",
    "    grad = gradient_function(w, X_train, y_train)\n",
    "    w = w - step * grad\n",
    "    \n",
    "    # Calculate weights till tolerance is reached or the maximum number of iterations\n",
    "    for i in range(iters):\n",
    "        grad = gradient_function(w, X_train, y_train)\n",
    "        w = w - step * grad\n",
    "        if np.absolute(np.linalg.norm(grad)) < epsilon:\n",
    "            print(f'Tolerance reached, stopped after {i+1} iterations')\n",
    "            break\n",
    "        grad_mag = np.absolute(np.linalg.norm(grad))\n",
    "    print(f'The Gradient Norm after {i+1} iterations with Gamma = {step}, tolerance = {epsilon} is {round(grad_mag,2)}')\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34d2499b-99ea-4505-b328-a9b1892748b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(w, X):\n",
    "    prob = 1/(1 + np.exp(-1 * np.dot(w, X)))\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b975476-092d-4e8b-aa10-d4b392010394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_classes(predicted, threshold):\n",
    "    result = []\n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i] <= threshold:\n",
    "            result.append(0)\n",
    "        else:\n",
    "            result.append(1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ff0b0fe-07ed-496d-97f1-f699ef61869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(actual, predicted):          \n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for i in range(len(actual)):\n",
    "        if ((predicted[i] == 1) & (actual[i] == 1)):\n",
    "            tp = tp + 1\n",
    "        elif ((predicted[i] == 1) & (actual[i] == 0)):\n",
    "            fp = fp + 1\n",
    "        elif ((predicted[i] == 0) & (actual[i] == 0)):\n",
    "            tn = tn + 1\n",
    "        elif ((predicted[i] == 0) & (actual[i] == 1)):\n",
    "            fn = fn + 1\n",
    "    \n",
    "    tpr = tp / (tp + fn)\n",
    "    tnr = tn / (tn + fp)\n",
    "    fnr = 1 - tpr\n",
    "    fpr = 1 - tnr\n",
    "    a = (tp + tn)/len(actual)\n",
    "    return round(tpr,3), round(fpr,3) , round(tnr,3), round(fnr,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859add02-415e-4f13-b744-818cea982110",
   "metadata": {},
   "source": [
    "#### Using different combination of max iterations, step sizes, and tolerances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a6b8622-474b-4850-9402-fede059814cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = {\n",
    "    'step_size': [0.00001, 0.00005, 0.000001],\n",
    "    'tolerance': [0.01, 0.001, 0.0001],\n",
    "    'max_iterations': [2000, 3000, 5000]\n",
    "}\n",
    "df_iteration = pd.DataFrame(None, columns=[\"step_size\", \"tolerance\", \"max_iterations\", \"recall\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3cf6ee0-d9a6-4e34-aa59-120115c936d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Gradient Norm after 2000 iterations with Gamma = 1e-05, tolerance = 0.01 is 1.19\n",
      "The Gradient Norm after 3000 iterations with Gamma = 1e-05, tolerance = 0.01 is 0.79\n",
      "The Gradient Norm after 5000 iterations with Gamma = 1e-05, tolerance = 0.01 is 0.47\n",
      "The Gradient Norm after 2000 iterations with Gamma = 1e-05, tolerance = 0.001 is 1.19\n",
      "The Gradient Norm after 3000 iterations with Gamma = 1e-05, tolerance = 0.001 is 0.79\n",
      "The Gradient Norm after 5000 iterations with Gamma = 1e-05, tolerance = 0.001 is 0.47\n",
      "The Gradient Norm after 2000 iterations with Gamma = 1e-05, tolerance = 0.0001 is 1.19\n",
      "The Gradient Norm after 3000 iterations with Gamma = 1e-05, tolerance = 0.0001 is 0.79\n",
      "The Gradient Norm after 5000 iterations with Gamma = 1e-05, tolerance = 0.0001 is 0.47\n",
      "The Gradient Norm after 2000 iterations with Gamma = 5e-05, tolerance = 0.01 is 0.73\n",
      "The Gradient Norm after 3000 iterations with Gamma = 5e-05, tolerance = 0.01 is 0.68\n",
      "The Gradient Norm after 5000 iterations with Gamma = 5e-05, tolerance = 0.01 is 0.67\n",
      "The Gradient Norm after 2000 iterations with Gamma = 5e-05, tolerance = 0.001 is 0.73\n",
      "The Gradient Norm after 3000 iterations with Gamma = 5e-05, tolerance = 0.001 is 0.68\n",
      "The Gradient Norm after 5000 iterations with Gamma = 5e-05, tolerance = 0.001 is 0.67\n",
      "The Gradient Norm after 2000 iterations with Gamma = 5e-05, tolerance = 0.0001 is 0.73\n",
      "The Gradient Norm after 3000 iterations with Gamma = 5e-05, tolerance = 0.0001 is 0.68\n",
      "The Gradient Norm after 5000 iterations with Gamma = 5e-05, tolerance = 0.0001 is 0.67\n",
      "The Gradient Norm after 2000 iterations with Gamma = 1e-06, tolerance = 0.01 is 6.84\n",
      "The Gradient Norm after 3000 iterations with Gamma = 1e-06, tolerance = 0.01 is 5.4\n",
      "The Gradient Norm after 5000 iterations with Gamma = 1e-06, tolerance = 0.01 is 3.87\n",
      "The Gradient Norm after 2000 iterations with Gamma = 1e-06, tolerance = 0.001 is 6.84\n",
      "The Gradient Norm after 3000 iterations with Gamma = 1e-06, tolerance = 0.001 is 5.4\n",
      "The Gradient Norm after 5000 iterations with Gamma = 1e-06, tolerance = 0.001 is 3.87\n",
      "The Gradient Norm after 2000 iterations with Gamma = 1e-06, tolerance = 0.0001 is 6.84\n",
      "The Gradient Norm after 3000 iterations with Gamma = 1e-06, tolerance = 0.0001 is 5.4\n",
      "The Gradient Norm after 5000 iterations with Gamma = 1e-06, tolerance = 0.0001 is 3.87\n"
     ]
    }
   ],
   "source": [
    "# Looping over all combinations of termination criteria\n",
    "for i in combinations['step_size']:\n",
    "    for j in combinations['tolerance']:\n",
    "        for k in combinations['max_iterations']:\n",
    "            w = np.zeros(d)\n",
    "            weight = logistic_regression(w, X_train, y_train, k, i, j)\n",
    "            pred_proba = calc_pred_proba(X_train, weight)\n",
    "            y_pred = predict_classes(pred_proba, 0.5)\n",
    "\n",
    "            # Calculate the recall and accuracy of the model on the train data\n",
    "            recall = recall_score(y_train, y_pred)\n",
    "            accuracy = accuracy_score(y_train, y_pred)\n",
    "            temp = pd.DataFrame([[i, k, j, accuracy, recall]],\n",
    "                                   columns=[\"step_size\",  \"max_iterations\", \"tolerance\", \"accuracy\", \"recall\",])\n",
    "            df_iteration = pd.concat([df_iteration, temp], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4902f4c7-1182-4904-a1a7-e94de7335422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_size</th>\n",
       "      <th>tolerance</th>\n",
       "      <th>max_iterations</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.850877</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.850877</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.850877</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.850877</td>\n",
       "      <td>0.913333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.850877</td>\n",
       "      <td>0.913333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    step_size  tolerance max_iterations    recall  accuracy\n",
       "10    0.00005     0.0100           3000  0.850877  0.916667\n",
       "13    0.00005     0.0010           3000  0.850877  0.916667\n",
       "16    0.00005     0.0001           3000  0.850877  0.916667\n",
       "9     0.00005     0.0100           2000  0.850877  0.913333\n",
       "11    0.00005     0.0100           5000  0.850877  0.913333"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iteration = df_iteration.sort_values(by=['accuracy', 'recall'], ascending=[False, False])\n",
    "df_iteration.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1157d18f-b018-47ed-86d5-370617535964",
   "metadata": {},
   "source": [
    "We have best recall score when step size = 0.00005, max_iterations = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "208bc650-5f49-469f-991f-2159188be3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Gradient Norm after 3000 iterations with Gamma = 5e-05, tolerance = 0.01 is 0.68\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros(d)\n",
    "weight = logistic_regression(w, X_train, y_train, 3000, 0.00005, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68afe1ac-e4ba-4855-bc35-da164a078bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radius_mean</td>\n",
       "      <td>-0.020186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>texture_mean</td>\n",
       "      <td>-0.017039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perimeter_mean</td>\n",
       "      <td>-0.104330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area_mean</td>\n",
       "      <td>-0.029616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smoothness_mean</td>\n",
       "      <td>-0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>compactness_mean</td>\n",
       "      <td>0.000458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>concavity_mean</td>\n",
       "      <td>0.000871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>concave points_mean</td>\n",
       "      <td>0.000356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>symmetry_mean</td>\n",
       "      <td>-0.000246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fractal_dimension_mean</td>\n",
       "      <td>-0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>radius_se</td>\n",
       "      <td>-0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>texture_se</td>\n",
       "      <td>-0.001511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>perimeter_se</td>\n",
       "      <td>0.002842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>area_se</td>\n",
       "      <td>0.043993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>smoothness_se</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>compactness_se</td>\n",
       "      <td>0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>concavity_se</td>\n",
       "      <td>0.000188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>concave points_se</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>symmetry_se</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fractal_dimension_se</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>radius_worst</td>\n",
       "      <td>-0.021359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>texture_worst</td>\n",
       "      <td>-0.020369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>perimeter_worst</td>\n",
       "      <td>-0.087329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>area_worst</td>\n",
       "      <td>0.046808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>smoothness_worst</td>\n",
       "      <td>-0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>compactness_worst</td>\n",
       "      <td>0.001584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>concavity_worst</td>\n",
       "      <td>0.002119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>concave points_worst</td>\n",
       "      <td>0.000571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>symmetry_worst</td>\n",
       "      <td>-0.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>fractal_dimension_worst</td>\n",
       "      <td>-0.000035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Features  Coefficients\n",
       "0               radius_mean     -0.020186\n",
       "1              texture_mean     -0.017039\n",
       "2            perimeter_mean     -0.104330\n",
       "3                 area_mean     -0.029616\n",
       "4           smoothness_mean     -0.000100\n",
       "5          compactness_mean      0.000458\n",
       "6            concavity_mean      0.000871\n",
       "7       concave points_mean      0.000356\n",
       "8             symmetry_mean     -0.000246\n",
       "9    fractal_dimension_mean     -0.000113\n",
       "10                radius_se     -0.000080\n",
       "11               texture_se     -0.001511\n",
       "12             perimeter_se      0.002842\n",
       "13                  area_se      0.043993\n",
       "14            smoothness_se      0.000010\n",
       "15           compactness_se      0.000133\n",
       "16             concavity_se      0.000188\n",
       "17        concave points_se      0.000047\n",
       "18              symmetry_se      0.000002\n",
       "19     fractal_dimension_se      0.000006\n",
       "20             radius_worst     -0.021359\n",
       "21            texture_worst     -0.020369\n",
       "22          perimeter_worst     -0.087329\n",
       "23               area_worst      0.046808\n",
       "24         smoothness_worst     -0.000082\n",
       "25        compactness_worst      0.001584\n",
       "26          concavity_worst      0.002119\n",
       "27     concave points_worst      0.000571\n",
       "28           symmetry_worst     -0.000224\n",
       "29  fractal_dimension_worst     -0.000035"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_coeff = {'Features':df_train.iloc[:,:-1].columns.values.tolist(), 'Coefficients': weight }\n",
    "df_coeff = pd.DataFrame(dict_coeff)\n",
    "df_coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971beca9-599d-4c72-8e0b-061bda51f092",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d58be27d-2dcf-425e-9610-1a203b530ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = calc_pred_proba(X_test, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e76bf781-df73-4d53-bf21-b80fab1c330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14a0b6b1-a00d-486c-932d-414afbcb45da",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for threshold in thresholds:\n",
    "    y_pred = predict_classes(pred_proba, threshold)\n",
    "    tpr, fpr, tnr, fnr = calc_metrics(y_test, y_pred)\n",
    "    metrics_dict = {'Threshold':threshold, 'TPR':tpr, 'FPR':fpr, 'TNR':tnr, 'FNR':fnr}\n",
    "    metrics.append(metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2de4f9d4-8b01-4899-8ad4-90299ab49ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TNR</th>\n",
       "      <th>FNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold    TPR    FPR    TNR    FNR\n",
       "0         0.0  1.000  1.000  0.000  0.000\n",
       "1         0.1  0.959  0.205  0.795  0.041\n",
       "2         0.2  0.918  0.123  0.877  0.082\n",
       "3         0.3  0.898  0.105  0.895  0.102\n",
       "4         0.4  0.878  0.064  0.936  0.122\n",
       "5         0.5  0.878  0.047  0.953  0.122\n",
       "6         0.6  0.867  0.041  0.959  0.133\n",
       "7         0.7  0.867  0.041  0.959  0.133\n",
       "8         0.8  0.847  0.029  0.971  0.153\n",
       "9         0.9  0.827  0.012  0.988  0.173\n",
       "10        1.0  0.000  0.000  1.000  1.000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics = pd.DataFrame(metrics)\n",
    "df_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
