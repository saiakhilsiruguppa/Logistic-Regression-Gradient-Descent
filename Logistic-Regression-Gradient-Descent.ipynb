{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f079bd1-d8a8-4085-ab6d-b06886bab5e4",
   "metadata": {},
   "source": [
    "# Logistic Regression and Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa5ef9c-7eea-4123-900c-4787546c8e8f",
   "metadata": {},
   "source": [
    "The file LRTrain.csv contains information from 300 images of malignant (i.e. cancerous) and\n",
    "benign (i.e., non-cancerous) breast tissue. The data set describes attributes of the cell nuclei in\n",
    "each image. Each row of the dataset corresponds to one image. For each image, ten different\n",
    "attributes related to the cell nuclei are recorded:\n",
    "\n",
    "- radius (mean of distances from center to points on the perimeter)\n",
    "- texture (standard deviation of gray-scale values)\n",
    "- perimeter\n",
    "- area\n",
    "- smoothness (local variation in radius lengths)\n",
    "- compactness (perimeter2/ area - 1.0)\n",
    "- concavity (severity of concave portions of the contour)\n",
    "- concave points (number of concave portions of the contour)\n",
    "- symmetry\n",
    "- fractal dimension (a measure of how “complex” the perimeter is)\n",
    "\n",
    "Because each image contains multiple cell nuclei, three quantities are measured for each of the 10\n",
    "attributes above: the mean, standard error, and worst case value. This results in a total of 30\n",
    "features for each image. The goal of this assignment is to train a logistic regression classifier using\n",
    "gradient descent, which will then be used to predict whether or not each image was taken from\n",
    "cancerous tissue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1af7ef7-3abb-4358-b443-ad32602f6888",
   "metadata": {},
   "source": [
    "<img src=\"image.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad44e87-ddf6-48a6-9301-e4568db78cad",
   "metadata": {},
   "source": [
    "We can minimize the cost function using the Gradient Descent algorithm where we differentiate the cost function to move in the direction of the global minima point. We need to calculate the gradient at a point w for the negative log likelihood function which is:\n",
    "\n",
    "$\\frac{1}{n} \\sum_{i=1}^{n} (\\frac{1}{1+ \\exp^{{-w}^Tx_i}} - y_i).x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cae163-cd8b-42ed-aa02-bbe558d775ee",
   "metadata": {},
   "source": [
    "We can use a step size to update the weights accordingly.\n",
    "\n",
    "$ x(i+1) = x(i) - (step\\ size)* \\frac{dy}{dx} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd09133-d0e4-4f42-8623-c47c19d6ce00",
   "metadata": {},
   "source": [
    "Check if $|{\\frac{dy}{dx}}| \\le \\epsilon$ and terminate if yes. Otherwise increment $i$ and return to previous steps mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa70d17e-e770-422a-8c71-7063d7b82d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gurobi and numpy\n",
    "from gurobipy import *\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ecdd424-3982-4855-9056-924ae7b9ceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('LRTrain.csv')\n",
    "df_test = pd.read_csv('LRTest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d73463a-ba5c-4a0c-9e5c-4a05274ff8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.180</td>\n",
       "      <td>20.52</td>\n",
       "      <td>77.22</td>\n",
       "      <td>458.7</td>\n",
       "      <td>0.08013</td>\n",
       "      <td>0.04038</td>\n",
       "      <td>0.02383</td>\n",
       "      <td>0.01770</td>\n",
       "      <td>0.1739</td>\n",
       "      <td>0.05677</td>\n",
       "      <td>...</td>\n",
       "      <td>32.84</td>\n",
       "      <td>84.58</td>\n",
       "      <td>547.8</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.08862</td>\n",
       "      <td>0.1145</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2694</td>\n",
       "      <td>0.06878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.280</td>\n",
       "      <td>22.41</td>\n",
       "      <td>98.92</td>\n",
       "      <td>710.6</td>\n",
       "      <td>0.09057</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.05375</td>\n",
       "      <td>0.03263</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>0.06317</td>\n",
       "      <td>...</td>\n",
       "      <td>28.03</td>\n",
       "      <td>113.80</td>\n",
       "      <td>973.1</td>\n",
       "      <td>0.1301</td>\n",
       "      <td>0.32990</td>\n",
       "      <td>0.3630</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.09772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.760</td>\n",
       "      <td>14.74</td>\n",
       "      <td>94.87</td>\n",
       "      <td>668.7</td>\n",
       "      <td>0.08875</td>\n",
       "      <td>0.07780</td>\n",
       "      <td>0.04608</td>\n",
       "      <td>0.03528</td>\n",
       "      <td>0.1521</td>\n",
       "      <td>0.05912</td>\n",
       "      <td>...</td>\n",
       "      <td>17.93</td>\n",
       "      <td>114.20</td>\n",
       "      <td>880.8</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.20090</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>0.12510</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.08187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.190</td>\n",
       "      <td>23.81</td>\n",
       "      <td>92.87</td>\n",
       "      <td>610.7</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.13060</td>\n",
       "      <td>0.11150</td>\n",
       "      <td>0.06462</td>\n",
       "      <td>0.2235</td>\n",
       "      <td>0.06433</td>\n",
       "      <td>...</td>\n",
       "      <td>34.85</td>\n",
       "      <td>115.00</td>\n",
       "      <td>811.3</td>\n",
       "      <td>0.1559</td>\n",
       "      <td>0.40590</td>\n",
       "      <td>0.3744</td>\n",
       "      <td>0.17720</td>\n",
       "      <td>0.4724</td>\n",
       "      <td>0.10260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.876</td>\n",
       "      <td>19.40</td>\n",
       "      <td>63.95</td>\n",
       "      <td>298.3</td>\n",
       "      <td>0.10050</td>\n",
       "      <td>0.09697</td>\n",
       "      <td>0.06154</td>\n",
       "      <td>0.03029</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.06322</td>\n",
       "      <td>...</td>\n",
       "      <td>26.83</td>\n",
       "      <td>72.22</td>\n",
       "      <td>361.2</td>\n",
       "      <td>0.1559</td>\n",
       "      <td>0.23020</td>\n",
       "      <td>0.2644</td>\n",
       "      <td>0.09749</td>\n",
       "      <td>0.2622</td>\n",
       "      <td>0.08490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0       12.180         20.52           77.22      458.7          0.08013   \n",
       "1       15.280         22.41           98.92      710.6          0.09057   \n",
       "2       14.760         14.74           94.87      668.7          0.08875   \n",
       "3       14.190         23.81           92.87      610.7          0.09463   \n",
       "4        9.876         19.40           63.95      298.3          0.10050   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0           0.04038         0.02383              0.01770         0.1739   \n",
       "1           0.10520         0.05375              0.03263         0.1727   \n",
       "2           0.07780         0.04608              0.03528         0.1521   \n",
       "3           0.13060         0.11150              0.06462         0.2235   \n",
       "4           0.09697         0.06154              0.03029         0.1945   \n",
       "\n",
       "   fractal_dimension_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
       "0                 0.05677  ...          32.84            84.58       547.8   \n",
       "1                 0.06317  ...          28.03           113.80       973.1   \n",
       "2                 0.05912  ...          17.93           114.20       880.8   \n",
       "3                 0.06433  ...          34.85           115.00       811.3   \n",
       "4                 0.06322  ...          26.83            72.22       361.2   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1123            0.08862           0.1145               0.07431   \n",
       "1            0.1301            0.32990           0.3630               0.12260   \n",
       "2            0.1220            0.20090           0.2151               0.12510   \n",
       "3            0.1559            0.40590           0.3744               0.17720   \n",
       "4            0.1559            0.23020           0.2644               0.09749   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  diagnosis  \n",
       "0          0.2694                  0.06878          0  \n",
       "1          0.3175                  0.09772          1  \n",
       "2          0.3109                  0.08187          0  \n",
       "3          0.4724                  0.10260          1  \n",
       "4          0.2622                  0.08490          0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db7a61e8-964f-4d4a-a4a9-6ac19b641d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['diagnosis'].to_numpy()\n",
    "X_train = df_train.drop('diagnosis', axis=1).to_numpy()\n",
    "y_test = df_test['diagnosis'].to_numpy()\n",
    "X_test = df_test.drop('diagnosis', axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c3785de-07c5-481a-ae4e-c5d08bc817de",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 300\n",
    "d = 30\n",
    "gamma = 0.00003\n",
    "epsilon = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a10baad0-8b2c-45ca-8405-d3462446ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.zeros(d)\n",
    "total_grad = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1994fca5-315b-4508-bbdd-957145e66f7f",
   "metadata": {},
   "source": [
    "#### Define function for calculating the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f7ea833-3aa8-4d94-889d-098a11f712a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_function(w, X_train, y_train):\n",
    "    n = len(X_train)\n",
    "    d = len(w)\n",
    "    sum_of_grad = np.zeros(d)\n",
    "    \n",
    "    for i in range(n):\n",
    "        x_i = X_train[i]\n",
    "        y_i = y_train[i]\n",
    "        to_add = ((1/(1+np.exp(-1 * np.dot(w, x_i), dtype=np.float128))) - y_i) * x_i\n",
    "        sum_of_grad += to_add\n",
    "    grad = sum_of_grad/n\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d25e89-5bc5-4397-8b73-4526374c3c39",
   "metadata": {},
   "source": [
    "#### Define function for computing weights for logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "809d49b5-2610-4b11-bf17-a5578410228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(w, X_train, y_train, iters, step, epsilon):\n",
    "    num_iter = 0\n",
    "    grad = gradient_function(w, X_train, y_train)\n",
    "    w = w - step * grad\n",
    "    \n",
    "    # Calculate weights till tolerance is reached or the maximum number of iterations\n",
    "    for i in range(iters):\n",
    "        grad = gradient_function(w, X_train, y_train)\n",
    "        w = w - step * grad\n",
    "        if np.absolute(np.linalg.norm(grad)) < epsilon:\n",
    "            print(f'Tolerance reached, stopped after {i+1} iterations')\n",
    "            break\n",
    "        grad_mag = np.absolute(np.linalg.norm(grad))\n",
    "    print(f'The Gradient Norm after {i+1} iterations with Gamma = {step}, tolerance = {epsilon} is {round(grad_mag,2)}')\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34d2499b-99ea-4505-b328-a9b1892748b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(w, X):\n",
    "    prob = 1/(1 + np.exp(-1 * np.dot(w, X)))\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b975476-092d-4e8b-aa10-d4b392010394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_classes(predicted, threshold):\n",
    "    result = []\n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i] <= threshold:\n",
    "            result.append(0)\n",
    "        else:\n",
    "            result.append(1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ff0b0fe-07ed-496d-97f1-f699ef61869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(actual, predicted):          \n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for i in range(len(actual)):\n",
    "        if ((predicted[i] == 1) & (actual[i] == 1)):\n",
    "            tp = tp + 1\n",
    "        elif ((predicted[i] == 1) & (actual[i] == 0)):\n",
    "            fp = fp + 1\n",
    "        elif ((predicted[i] == 0) & (actual[i] == 0)):\n",
    "            tn = tn + 1\n",
    "        elif ((predicted[i] == 0) & (actual[i] == 1)):\n",
    "            fn = fn + 1\n",
    "    \n",
    "    tpr = tp / (tp + fn)\n",
    "    tnr = tn / (tn + fp)\n",
    "    fnr = 1 - tpr\n",
    "    fpr = 1 - tnr\n",
    "    a = (tp + tn)/len(actual)\n",
    "    return round(tpr,3), round(fpr,3) , round(tnr,3), round(fnr,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859add02-415e-4f13-b744-818cea982110",
   "metadata": {},
   "source": [
    "#### Using different combination of max iterations, step sizes, and tolerances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a6b8622-474b-4850-9402-fede059814cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = {\n",
    "    'step_size': [0.00001, 0.00005, 0.000001],\n",
    "    'tolerance': [0.01, 0.001, 0.0001],\n",
    "    'max_iterations': [2000, 3000, 5000]\n",
    "}\n",
    "df_iteration = pd.DataFrame(None, columns=[\"step_size\", \"tolerance\", \"max_iterations\", \"recall\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3cf6ee0-d9a6-4e34-aa59-120115c936d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Gradient Norm after 2000 iterations with Gamma = 1e-05, tolerance = 0.01 is 1.19\n",
      "The Gradient Norm after 3000 iterations with Gamma = 1e-05, tolerance = 0.01 is 0.79\n",
      "The Gradient Norm after 5000 iterations with Gamma = 1e-05, tolerance = 0.01 is 0.47\n",
      "The Gradient Norm after 2000 iterations with Gamma = 1e-05, tolerance = 0.001 is 1.19\n",
      "The Gradient Norm after 3000 iterations with Gamma = 1e-05, tolerance = 0.001 is 0.79\n",
      "The Gradient Norm after 5000 iterations with Gamma = 1e-05, tolerance = 0.001 is 0.47\n",
      "The Gradient Norm after 2000 iterations with Gamma = 1e-05, tolerance = 0.0001 is 1.19\n",
      "The Gradient Norm after 3000 iterations with Gamma = 1e-05, tolerance = 0.0001 is 0.79\n",
      "The Gradient Norm after 5000 iterations with Gamma = 1e-05, tolerance = 0.0001 is 0.47\n",
      "The Gradient Norm after 2000 iterations with Gamma = 5e-05, tolerance = 0.01 is 0.73\n",
      "The Gradient Norm after 3000 iterations with Gamma = 5e-05, tolerance = 0.01 is 0.68\n",
      "The Gradient Norm after 5000 iterations with Gamma = 5e-05, tolerance = 0.01 is 0.67\n",
      "The Gradient Norm after 2000 iterations with Gamma = 5e-05, tolerance = 0.001 is 0.73\n",
      "The Gradient Norm after 3000 iterations with Gamma = 5e-05, tolerance = 0.001 is 0.68\n",
      "The Gradient Norm after 5000 iterations with Gamma = 5e-05, tolerance = 0.001 is 0.67\n",
      "The Gradient Norm after 2000 iterations with Gamma = 5e-05, tolerance = 0.0001 is 0.73\n",
      "The Gradient Norm after 3000 iterations with Gamma = 5e-05, tolerance = 0.0001 is 0.68\n",
      "The Gradient Norm after 5000 iterations with Gamma = 5e-05, tolerance = 0.0001 is 0.67\n",
      "The Gradient Norm after 2000 iterations with Gamma = 1e-06, tolerance = 0.01 is 6.84\n",
      "The Gradient Norm after 3000 iterations with Gamma = 1e-06, tolerance = 0.01 is 5.4\n",
      "The Gradient Norm after 5000 iterations with Gamma = 1e-06, tolerance = 0.01 is 3.87\n",
      "The Gradient Norm after 2000 iterations with Gamma = 1e-06, tolerance = 0.001 is 6.84\n",
      "The Gradient Norm after 3000 iterations with Gamma = 1e-06, tolerance = 0.001 is 5.4\n",
      "The Gradient Norm after 5000 iterations with Gamma = 1e-06, tolerance = 0.001 is 3.87\n",
      "The Gradient Norm after 2000 iterations with Gamma = 1e-06, tolerance = 0.0001 is 6.84\n",
      "The Gradient Norm after 3000 iterations with Gamma = 1e-06, tolerance = 0.0001 is 5.4\n",
      "The Gradient Norm after 5000 iterations with Gamma = 1e-06, tolerance = 0.0001 is 3.87\n"
     ]
    }
   ],
   "source": [
    "# Looping over all combinations of termination criteria\n",
    "for i in combinations['step_size']:\n",
    "    for j in combinations['tolerance']:\n",
    "        for k in combinations['max_iterations']:\n",
    "            w = np.zeros(d)\n",
    "            weight = logistic_regression(w, X_train, y_train, k, i, j)\n",
    "            pred_proba = calc_pred_proba(X_train, weight)\n",
    "            y_pred = predict_classes(pred_proba, 0.5)\n",
    "\n",
    "            # Calculate the recall and accuracy of the model on the train data\n",
    "            recall = recall_score(y_train, y_pred)\n",
    "            accuracy = accuracy_score(y_train, y_pred)\n",
    "            temp = pd.DataFrame([[i, k, j, accuracy, recall]],\n",
    "                                   columns=[\"step_size\",  \"max_iterations\", \"tolerance\", \"accuracy\", \"recall\",])\n",
    "            df_iteration = pd.concat([df_iteration, temp], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4902f4c7-1182-4904-a1a7-e94de7335422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_size</th>\n",
       "      <th>tolerance</th>\n",
       "      <th>max_iterations</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.850877</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.850877</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.850877</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.850877</td>\n",
       "      <td>0.913333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.850877</td>\n",
       "      <td>0.913333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    step_size  tolerance max_iterations    recall  accuracy\n",
       "10    0.00005     0.0100           3000  0.850877  0.916667\n",
       "13    0.00005     0.0010           3000  0.850877  0.916667\n",
       "16    0.00005     0.0001           3000  0.850877  0.916667\n",
       "9     0.00005     0.0100           2000  0.850877  0.913333\n",
       "11    0.00005     0.0100           5000  0.850877  0.913333"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iteration = df_iteration.sort_values(by=['accuracy', 'recall'], ascending=[False, False])\n",
    "df_iteration.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1157d18f-b018-47ed-86d5-370617535964",
   "metadata": {},
   "source": [
    "We have best recall score when step size = 0.00005, max_iterations = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "208bc650-5f49-469f-991f-2159188be3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Gradient Norm after 3000 iterations with Gamma = 5e-05, tolerance = 0.01 is 0.68\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros(d)\n",
    "weight = logistic_regression(w, X_train, y_train, 3000, 0.00005, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68afe1ac-e4ba-4855-bc35-da164a078bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radius_mean</td>\n",
       "      <td>-0.020186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>texture_mean</td>\n",
       "      <td>-0.017039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perimeter_mean</td>\n",
       "      <td>-0.104330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area_mean</td>\n",
       "      <td>-0.029616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smoothness_mean</td>\n",
       "      <td>-0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>compactness_mean</td>\n",
       "      <td>0.000458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>concavity_mean</td>\n",
       "      <td>0.000871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>concave points_mean</td>\n",
       "      <td>0.000356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>symmetry_mean</td>\n",
       "      <td>-0.000246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fractal_dimension_mean</td>\n",
       "      <td>-0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>radius_se</td>\n",
       "      <td>-0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>texture_se</td>\n",
       "      <td>-0.001511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>perimeter_se</td>\n",
       "      <td>0.002842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>area_se</td>\n",
       "      <td>0.043993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>smoothness_se</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>compactness_se</td>\n",
       "      <td>0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>concavity_se</td>\n",
       "      <td>0.000188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>concave points_se</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>symmetry_se</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fractal_dimension_se</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>radius_worst</td>\n",
       "      <td>-0.021359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>texture_worst</td>\n",
       "      <td>-0.020369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>perimeter_worst</td>\n",
       "      <td>-0.087329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>area_worst</td>\n",
       "      <td>0.046808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>smoothness_worst</td>\n",
       "      <td>-0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>compactness_worst</td>\n",
       "      <td>0.001584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>concavity_worst</td>\n",
       "      <td>0.002119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>concave points_worst</td>\n",
       "      <td>0.000571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>symmetry_worst</td>\n",
       "      <td>-0.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>fractal_dimension_worst</td>\n",
       "      <td>-0.000035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Features  Coefficients\n",
       "0               radius_mean     -0.020186\n",
       "1              texture_mean     -0.017039\n",
       "2            perimeter_mean     -0.104330\n",
       "3                 area_mean     -0.029616\n",
       "4           smoothness_mean     -0.000100\n",
       "5          compactness_mean      0.000458\n",
       "6            concavity_mean      0.000871\n",
       "7       concave points_mean      0.000356\n",
       "8             symmetry_mean     -0.000246\n",
       "9    fractal_dimension_mean     -0.000113\n",
       "10                radius_se     -0.000080\n",
       "11               texture_se     -0.001511\n",
       "12             perimeter_se      0.002842\n",
       "13                  area_se      0.043993\n",
       "14            smoothness_se      0.000010\n",
       "15           compactness_se      0.000133\n",
       "16             concavity_se      0.000188\n",
       "17        concave points_se      0.000047\n",
       "18              symmetry_se      0.000002\n",
       "19     fractal_dimension_se      0.000006\n",
       "20             radius_worst     -0.021359\n",
       "21            texture_worst     -0.020369\n",
       "22          perimeter_worst     -0.087329\n",
       "23               area_worst      0.046808\n",
       "24         smoothness_worst     -0.000082\n",
       "25        compactness_worst      0.001584\n",
       "26          concavity_worst      0.002119\n",
       "27     concave points_worst      0.000571\n",
       "28           symmetry_worst     -0.000224\n",
       "29  fractal_dimension_worst     -0.000035"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_coeff = {'Features':df_train.iloc[:,:-1].columns.values.tolist(), 'Coefficients': weight }\n",
    "df_coeff = pd.DataFrame(dict_coeff)\n",
    "df_coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971beca9-599d-4c72-8e0b-061bda51f092",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d58be27d-2dcf-425e-9610-1a203b530ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = calc_pred_proba(X_test, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e76bf781-df73-4d53-bf21-b80fab1c330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14a0b6b1-a00d-486c-932d-414afbcb45da",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for threshold in thresholds:\n",
    "    y_pred = predict_classes(pred_proba, threshold)\n",
    "    tpr, fpr, tnr, fnr = calc_metrics(y_test, y_pred)\n",
    "    metrics_dict = {'Threshold':threshold, 'TPR':tpr, 'FPR':fpr, 'TNR':tnr, 'FNR':fnr}\n",
    "    metrics.append(metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2de4f9d4-8b01-4899-8ad4-90299ab49ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TNR</th>\n",
       "      <th>FNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold    TPR    FPR    TNR    FNR\n",
       "0         0.0  1.000  1.000  0.000  0.000\n",
       "1         0.1  0.959  0.205  0.795  0.041\n",
       "2         0.2  0.918  0.123  0.877  0.082\n",
       "3         0.3  0.898  0.105  0.895  0.102\n",
       "4         0.4  0.878  0.064  0.936  0.122\n",
       "5         0.5  0.878  0.047  0.953  0.122\n",
       "6         0.6  0.867  0.041  0.959  0.133\n",
       "7         0.7  0.867  0.041  0.959  0.133\n",
       "8         0.8  0.847  0.029  0.971  0.153\n",
       "9         0.9  0.827  0.012  0.988  0.173\n",
       "10        1.0  0.000  0.000  1.000  1.000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics = pd.DataFrame(metrics)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ffaa072-2462-4835-acf1-9d10a5427417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = calc_pred_proba(X_test, weight)\n",
    "preds = probs\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
